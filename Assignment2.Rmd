---
title: "Assignment2"
author: "Jasmine"
date: "March 3, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(hdm)
library(ggplot2)
library(stargazer)
library(AER) #IV Regression
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```


#Problem 1: load and explore the data
```{r problem 1, echo=FALSE}
data(BLP)
tab2 <- c(3.393, 6.711, 8.728, 13.074, 68.597)
stopifnot(all(abs(quantile(BLP$price, c(0,0.25,0.5,0.75,1)) - tab2 +
                    11.761)<0.005))
BLP$price <- BLP$price + 11.761
BLP$trend <- BLP$trend + 1970
#Plots
M1 <- aggregate(BLP$model.id,by=list(BLP$trend),FUN=length)
p1 <- ggplot(M1,aes(x=Group.1,y=x)) + geom_point(shape=1) + xlab("year") + ylab("Number of Model")
M2 <- aggregate(BLP$price,by=list(BLP$trend),FUN=mean)
p2 <- ggplot(M2,aes(x=Group.1,y=x)) + geom_point(shape=1) +  geom_smooth(method=lm) + xlab("year") + ylab("Average Price")
M3 <- aggregate(BLP$mpg,by=list(BLP$trend),FUN=mean)
p3 <- ggplot(M3,aes(x=Group.1,y=x)) + geom_point(shape=1) +  geom_smooth(method=lm) + xlab("year") + ylab("MPG")
M4 <- aggregate(BLP$air,by=list(BLP$trend),FUN=mean)
p4 <- ggplot(M4,aes(x=Group.1,y=x)) + geom_point(shape=1) +  geom_smooth(method=lm) + xlab("year") + ylab("Air")
stargazer(BLP,type="text")
BLP$trend <- BLP$trend - 1970
multiplot(p1,p2,p3,p4,cols=2)

M5 <- aggregate(BLP$space,by=list(BLP$trend),FUN=mean)
M6 <- aggregate(BLP$hpwt,by=list(BLP$trend),FUN=mean)
tab <- cbind(M1,M2$x,M3$x,M4$x,M5$x,M6$x)
colnames(tab) <- c("year","No.model","Price","MPG","Air","Spce","HP/Wt")
stargazer(tab,type="text",summary=FALSE)
# ggplot(M1,aes(x=Group.1,y=x)) + geom_point(shape=1) + geom_smooth(method=lm)
```


## Problem 2: Logit Demand
```{r problem 2, echo=FALSE}
X <- as.matrix(cbind(1,BLP[,c("hpwt","air","mpg","space","outshr","share")]))
BLP$Z <- hdm:::constructIV(BLP$firm.id,BLP$cdid,BLP$id,X)
ols.reg <- lm(y ~ price + hpwt + air + mpd + space, data = BLP)
iv.reg <- ivreg(y ~ price + hpwt + air + mpd + space |Z + hpwt + air + mpd + space , data = BLP)
ols.reg2 <- lm(log(price) ~  hpwt + air  + mpg + trend + space, data = BLP)
stargazer(ols.reg,iv.reg,ols.reg2,type="text")
elasticity <- BLP$price  * ols.reg$coefficients[2] 
print(sum(abs(elasticity) < 1))
```
There are over a half observations with inelastic demand. This is inconsistent with the profit maximization assumptions.

## Problem 3: Shares and delta
```{r problem 2 test, echo=FALSE}
# S <- 100
# K <- 200
# J <- 10 #Assume there is only 10 models
# alpha <- 1
# log.y <- rnorm(S) * 0.840 + 3.082
# y <- exp(log.y)
# 
# v <- matrix(rnorm(S*K),nr=S)
# delta <- rnorm(J)
# p <- rnorm(J)
# sigma <- rnorm(K) #sigma is k in length
# x <- matrix(rnorm(J*K),nr=K)
# log.yp <- sapply(p, function(x){y - x})

share.fn <- function(delta,  ## J vector
                     x,      ## J by K
                     log.y,  ## S vector of log(y_i)
                     log.yp, ## S by J of log(y_i - p_j) 
                     v,      ## S by K
                     alpha,  ## scalar
                     sigma)  ## K vector
  {
  J <- length(delta)
  S <- length(log.y)
  K <- length(sigma)
  # exp.delta <- matrix(0,nr=J,nc=S)
  share <- rep(0,J)
  for (i in 1:S){
    share.each <-  exp(x %*% (sigma * v[i,]) + delta + alpha * log.yp[i,])
    share  <-  share + share.each / (sum(share.each) + exp(alpha*log.y[i]))
  }
  share <- share / S
  
  # stop("TODO: compute J vector of shares in this market")
  return(share)
}
# share.fn(delta,x,log.y,log.yp,v,alpha,sigma )

delta.fn <- function(s,x,log.y,log.yp,v,alpha,sigma,
                     tol=1e-6, tol.s=1e-8,
                     max.iter=100)
{
  delta.new <- log(s) - log(1-sum(s)) ## initial guess
  dd <- 1 ## ||change in delta||
  ds <- 1 ## ||observed shares - share.fn(delta)||
  iter <- 0
  J <- length(delta)
  S <- length(log.y)
  K <- length(sigma)
  exp.delta <- matrix(0,nr=J,nc=S)
  while ((dd>tol) | (ds>tol.s)) {
    delta.old <- delta.new
    
    # sm <- exp(delta.old) / (1 + sum(exp(delta.old) ))
    # for (i in 1:S){
    #    share.each <-  exp(x %*% (sigma * v[i,]) + delta.old)
    #    exp.delta[,i] <-  share.each / (sum(share.each) + 1)
    #  }
    # sm <- apply(exp.delta,1,mean)
    # log.sm <- sapply(sm , function(x)  ifelse(x>=0.1, log(x), log(0.1) + 10*(x-0.1)))
    # 
    sm  <- share.fn(delta.old,x,log.y,log.yp,v,alpha,sigma)
    delta.new <- delta.old  + log(s) - log(sm)
    # delta.new <- stop("## TODO: update delta using contraction mapping")
    dd <- max(abs(delta.old - delta.new))
    ds <- max(abs(s - sm))
    iter = iter+1
    if (dd < tol | ds < tol.s){
      break
    }
    
    if (iter>max.iter) {
      warning(sprintf("Maximum iterations (%d) reached, returning with norm(delta.new - delta.old) = %.2g", 
                   max.iter, dd))
      break;
    }
  }
  return(delta.new)
}
```
The test code for share.fn and delta.fn.
```{r Problem 2 Test, echo=FALSE,warning=FALSE}
#Test code
Z <- hdm:::constructIV(BLP$firm.id, BLP$cdid, BLP$id,
                       cbind(1,BLP[,c("hpwt","air","mpd","mpg","space","price")]))
## supply instruments
W <- log(BLP[,c("hpwt","mpg","space","mpd")])
colnames(W) <- paste("log",colnames(W),sep=".")
Wiv <- hdm:::constructIV(BLP$firm.id, BLP$cdid, BLP$id, W)

## Draws for simluting integral
S <- 100 
T <- length(unique(BLP$cdid))
K <- 5
set.seed(41658)
y.s <- matrix(exp(rnorm(S*T,mean=3.082, sd=0.840)),nrow=T,ncol=S)
v.s <- array(rnorm(S*T*K, mean=0,sd=1), dim=c(T,S,K))

## Estimates from Table IV of BLP -- used for comparison and testing
est.blp <- list(alpha=43.501, sigma=c(3.612, 4.628, 1.818, 1.050,
                                      2.056),
                beta=c(-7.061, 2.883, 1.521, -0.122, 3.460),
                gamma=c(0.952, 0.477, 0.619, -.415, -.049, .019))

## Put data into more convenient structure for estimation
est.data <- list(x=as.matrix(cbind(1,BLP[,c("hpwt","air","mpd","space")])),
                 w=as.matrix(cbind(1,log(BLP$hpwt), BLP$air, log(BLP$mpg),
                                   log(BLP$space), BLP$trend )))
est.data$zd <- as.matrix(cbind(est.data$x, Z))
est.data$zs <- as.matrix(cbind(est.data$w, Wiv))
est.data$log.y <- log(y.s)
est.data$log.yp <- list()

## BLP uses log(y - p) in utility function, but some vehicles have
## p>y for some people. BLP do not say what they did in this cases.
## I will take a first order Taylor expansion of log to the left of
## some small number to get an almost log function that is defined
## everywhere. This is very arbitrary though ....
x0 <- 0.1 ## take linear taylor approx to log around x0 for y-p<x0 to
logx0 <- log(x0)
slope <- 1/x0
## avoid log(-)
my.log <- function(x)  ifelse(x>=x0, log(x), logx0 + slope*(x-x0))
dmy.log <- function(x) ifelse(x>=x0, 1/x, slope)
for (t in 1:T) {
  yp <- outer(drop(y.s[t,]), BLP$price[BLP$cdid==t],
              function(x,y) x-y)
  est.data$log.yp[[t]] <- my.log(yp)
  est.data$dlog.yp[[t]] <- dmy.log(yp)
}

## Testing of delta.fn 
t <- 1
inc <- BLP$cdid==t
delta <- rnorm(n=length(BLP$price[inc]))
s <- share.fn(delta, x=drop(est.data$x[inc,]),
              log.y=drop(est.data$log.y[t,]),
              log.yp=est.data$log.yp[[t]],
              v=drop(v.s[t,,]),
              alpha=est.blp$alpha,
              sigma=est.blp$sigma)
d.check <- delta.fn(s, x=drop(est.data$x[inc,]),
                    log.y=drop(est.data$log.y[t,]),
                    log.yp=est.data$log.yp[[t]],
                    v=drop(v.s[t,,]),
                    alpha=est.blp$alpha,
                    sigma=est.blp$sigma, max.iter=10000)

print(summary((abs(delta-d.check))))
```
Check the derivative function is correct.
```{r Problem 2, echo=FALSE,warning=FALSE}
dshare.dp <- function(delta,x,log.y, log.yp, dlog.yp, v,alpha,sigma)
{
  J <- length(delta)
  S <- length(log.y)
  K <- length(sigma)
  sj.pj <- rep(0,J) #The diagonal line has a different method 
  sj.pk <- rep(0,J^2)
  for (i in 1:S){
    
    share.each <- exp(x %*% (sigma * v[i,]) + delta + alpha * log.yp[i,])
    share.each <- share.each / (sum(share.each) + exp(alpha*log.y[i]))
    sj.pj <- sj.pj + share.each * (1 - share.each) * ( - alpha * dlog.yp[i,])
    sj.pk <- sj.pk + as.vector(share.each %*% t((share.each * dlog.yp[i,]))) * alpha
  }
  tmp.1 <- diag(as.vector(sj.pj/S))
  tmp.2 <- matrix(sj.pk/S,nc=J)
  conv <- matrix(1,nc=J,nr=J) - diag(J)
  dshare <- t(tmp.2 * conv + tmp.1)
  return(dshare)
}

## Testing dshare.dp
if (!require(numDeriv)) install.packages("numDeriv")
library(numDeriv)
t <- 1
inc <- BLP$cdid==t
dshare.num <- jacobian(function(p) {
  yp <- outer(drop(y.s[t,]), p,
              function(x,y) x-y)
  share.fn(delta, x=drop(est.data$x[inc,]),
           log.y=drop(est.data$log.y[t,]),
           log.yp=my.log(yp),
           v=drop(v.s[t,,]),
           alpha=est.blp$alpha,
           sigma=est.blp$sigma)
}, x=BLP$price[inc])
dshare <- dshare.dp(delta, x=drop(est.data$x[inc,]),
           log.y=drop(est.data$log.y[t,]),
           log.yp=est.data$log.yp[[t]], 
           dlog.yp=est.data$dlog.yp[[t]] ,
           v=drop(v.s[t,,]),
           alpha=est.blp$alpha,
           sigma=est.blp$sigma)
print(summary(diag(dshare-dshare.num)))
print(summary(as.vector(dshare-dshare.num)))
```
## Problem 4: code optimization
```{r Problem 4, echo=FALSE}
moments <- function(alpha,sigma, s,p,x,log.yp, log.y,dlog.yp,
                    v,w,zd,zs, W,
                    market.id,firm.id, delta.tol=1e-10,
                    max.iter=100, compute.variance=FALSE)
{
  ## Find delta and omega for each market
  delta <- rep(NA, length(s))
  omega <- rep(NA, length(s))
  for (t in unique(market.id)) {
    inc <- market.id==t
    delta[inc] <-  delta.fn(s[inc], x[inc,],drop(log.y[t,]),
                           log.yp[[t]] ,
                           v=drop(v[t,,]),
                           alpha,sigma, tol=delta.tol,
                           tol.s=1e-6, max.iter=max.iter)
    
    dShare <- dshare.dp(delta[inc], x[inc,], drop(log.y[t,]),
                        log.yp[[t]], dlog.yp[[t]] , drop(v[t,,]), alpha,sigma)
    dShare <- dShare* outer(firm.id[inc],firm.id[inc],
                            function(x,y) x==y)
    b <- solve(dShare) %*% s[inc]
    omega[inc] <- log(p[inc]-b)
  }

  ## Solve for beta and gamma
  X <- as.matrix(rbind(cbind(x,0*w), cbind(0*x,w)))
  Y <- c(delta, omega)
  Z <- as.matrix(rbind(cbind(zd,0*zs), cbind(0*zd, zs)))
  XZ <- t(X) %*% Z 
  B <- solve(XZ %*% W %*% t(XZ)) %*%
    (XZ  %*% W %*% t(Z) %*% Y)
  beta <- B[1:ncol(x)]
  gamma <- B[(1+ncol(x)):(ncol(x)+ncol(w))]

  ## Compute GMM objective
  E <- Y - X %*% B
  g <- drop(E)*Z
  G <- colMeans(g)
  obj <- nrow(g)*t(G) %*% W %*% G
  if (compute.variance ){
    ZE <- apply(Z,2,function(x){x*E})
    Omega <- XZ  %*% W %*% t(ZE) %*% ZE %*% W %*% t(XZ)
    H_b <- solve(XZ %*% W %*% t(XZ))
    var <- H_b %*% Omega %*% H_b
  }else{
    var <- NULL
  }
   
  return(list(obj=obj, beta=beta, gamma=gamma,var = var))
}
```


```{r Problem 4 check, echo=FALSE, eval=FALSE}
Rprof("blp.prof", line.profiling=TRUE) # start the profiler

Z <- as.matrix(rbind(cbind(est.data$zd,0*est.data$zs), cbind(0*est.data$zd, est.data$zs)))
opt.weight <- solve(t(Z)%*% Z)
q <- moments(est.blp$alpha,est.blp$sigma,s=BLP$share,p=BLP$price,
             x=est.data$x, log.y=est.data$log.y,
             log.yp=est.data$log.yp,
             dlog.yp=est.data$dlog.yp,
             v=v.s,w=est.data$w,zd=est.data$zd,zs=est.data$zs,
             W=diag(1,nrow=(ncol(est.data$zd)+ncol(est.data$zs))),
             # W = opt.weight,
             market.id=BLP$cdid, firm.id=BLP$firm.id)
Rprof(NULL) # stop the profiler

summaryRprof("blp.prof", lines="both") # show the results
```
The inline functions and apply procedure takes most of the time. Share.fun first record all the values for each y draw, then take average. This apply function takes a lot of time, so instead of recording every draw of y, I sum up the share, and devide by S at the end. This is a similar case in function dshare.dp. The time is shortened by 90%. However, on the cost side, the parameters does not agree with the paper in sign. I doubt it is due to the construction of IV is not completely valid.
```{r redundent, echo=FALSE, eval=FALSE}
alpha = est.blp$alpha
sigma = est.blp$sigma
s = BLP$share
p = BLP$price
x=est.data$x 
log.y=est.data$log.y           
log.yp=est.data$log.yp
dlog.yp=est.data$dlog.yp             
v=v.s
w=est.data$w
zd=est.data$zd
zs=est.data$zs
W=diag(1,nrow=(ncol(est.data$zd)+ncol(est.data$zs)))
             # W = opt.weight,
market.id=BLP$cdid
firm.id=BLP$firm.id
delta.tol=1e-10
max.iter=100

Rprof("blp.prof", line.profiling=TRUE) # start the profiler

delta <- rep(NA, length(s))
omega <- rep(NA, length(s))
for (t in unique(market.id)) {
    inc <- market.id==t
    delta[inc] <-  delta.fn(s[inc], x[inc,],drop(log.y[t,]),
                           log.yp[[t]] ,
                           v=drop(v[t,,]),
                           alpha,sigma, tol=delta.tol,
                           tol.s=1e-6, max.iter=max.iter)
    
    dShare <- dshare.dp(delta[inc], x[inc,], drop(log.y[t,]),
                        log.yp[[t]], dlog.yp[[t]] , drop(v[t,,]), alpha,sigma)
    dShare <- dShare * outer(firm.id[inc],firm.id[inc],
                            function(x,y) x==y)
    b <- solve(dShare) %*% s[inc]
    omega[inc] <- log(p[inc]-b)
}
Rprof(NULL) # stop the profiler

summaryRprof("blp.prof", lines="both") # show the results

```

## Problem 5: estimation
```{r, echo=FALSE,eval=TRUE}

obj.func <- function(alpha.sigma) { m <-moments(alpha.sigma[1],alpha.sigma[2:6],s=BLP$share,p=BLP$price,
             x=est.data$x, log.y=est.data$log.y,
             log.yp=est.data$log.yp,
             dlog.yp=est.data$dlog.yp,
             v=v.s,w=est.data$w,
             zd=est.data$zd,
             zs=est.data$zs,
             W=diag(1,nrow=(ncol(est.data$zd)+ncol(est.data$zs))),
             # W = opt.weight,
             market.id=BLP$cdid, firm.id=BLP$firm.id)

              m$obj
}
library(nloptr)
x0 <- c(est.blp$alpha,est.blp$sigma)
obj.func(c(est.blp$alpha,est.blp$sigma))
step.a <- nloptr(x0=x0 ,eval_f = obj.func, lb = x0 * 0.1 , opts=list(algorithm="NLOPT_LN_BOBYQA",print_level=3,tol=1e-2))
step.b <- moments(sol[1],sol[2:6],s=BLP$share,p=BLP$price,
             x=est.data$x, log.y=est.data$log.y,
             log.yp=est.data$log.yp,
             dlog.yp=est.data$dlog.yp,
             v=v.s,w=est.data$w,
             zd=est.data$zd,
             zs=est.data$zs,
             W=diag(1,nrow=(ncol(est.data$zd)+ncol(est.data$zs))),
             # W = opt.weight,
             market.id=BLP$cdid, firm.id=BLP$firm.id, compute.variance = TRUE)


est.result.1 <- matrix(c( step.a$solution[1], step.a$solution[2:6],  step.b$beta,  step.b$gamma),nc=1)
rownames(est.result.1) <- c("alpha",paste("sigma",c("constant","hpwt","air","mpd","space"),sep = "."),paste("beta",c("constant","hpwt","air","mpd","space"),sep = "."),paste("gamma",c("constant","hpwt","air","mpd","space","trend"),sep = "."))

stargazer(est.result.1,type="text")
#,control = list("algorithm" = "NLOPT_LD_SBPLX" , "xtol_rel"=1.0e-2,
# "#print_level" = 2))
```
Compare to table IV in the BLP paper, the sign mostly agrees for beta. This implies that the demand side is correctly estimated. However, the supply side is not similar to the paper. The signs of gamma does not aggree.

```{r Problem 5 with opt.weight, echo=FALSE,eval=FALSE}
Z <- as.matrix(rbind(cbind(est.data$zd,0*est.data$zs), cbind(0*est.data$zd, est.data$zs)))
opt.weight <- solve(t(Z)%*% Z)
obj.func <- function(alpha.sigma) { m <-moments(alpha.sigma[1],alpha.sigma[2:6],s=BLP$share,p=BLP$price,
             x=est.data$x, log.y=est.data$log.y,
             log.yp=est.data$log.yp,
             dlog.yp=est.data$dlog.yp,
             v=v.s,w=est.data$w,
             zd=est.data$zd,
             zs=est.data$zs,
             # W=diag(1,nrow=(ncol(est.data$zd)+ncol(est.data$zs))),
             W = opt.weight,
             market.id=BLP$cdid, firm.id=BLP$firm.id)

              m$obj
}

x0 <- c(est.blp$alpha,est.blp$sigma)
obj.func(c(est.blp$alpha,est.blp$sigma))
step.a <- nloptr(x0=x0 ,eval_f = obj.func, lb = x0 * 0.1 , opts=list(algorithm="NLOPT_LN_BOBYQA",print_level=3,tol=1e-2))
step.b <- moments(sol[1],sol[2:6],s=BLP$share,p=BLP$price,
             x=est.data$x, log.y=est.data$log.y,
             log.yp=est.data$log.yp,
             dlog.yp=est.data$dlog.yp,
             v=v.s,w=est.data$w,
             zd=est.data$zd,
             zs=est.data$zs,
             W=diag(1,nrow=(ncol(est.data$zd)+ncol(est.data$zs))),
             # W = opt.weight,
             market.id=BLP$cdid, firm.id=BLP$firm.id,compute.variance = TRUE)



est.result.2 <- matrix(c( step.a$solution[1], step.a$solution[2:6],  step.b$beta,  step.b$gamma),nc=1)
rownames(est.result.2) <- c("alpha",paste("sigma",c("constant","hpwt","air","mpd","space"),sep = "."),paste("beta",c("constant","hpwt","air","mpd","space"),sep = "."),paste("gamma",c("constant","hpwt","air","mpd","space","trend"),sep = "."))

stargazer(est.result.2,type="text")

```
I tried to use weight matrix as the outer product of instruments. However, this result seems to be even worse. The scale of alpha is far away from the estimation.
## Problem 6:
```{r Problem 6, echo=FALSE}

```
